{
  "$schema": "./models.schema.json",
  "version": "1.0",
  "models": [
    {
      "id": "gpt-4.1",
      "name": "GPT-4.1",
      "provider": "openai",
      "isLocal": false,
      "contextWindow": 128000,
      "maxOutputTokens": 16384,
      "speed": "medium",
      "cost": "high",
      "description": "Most capable OpenAI model for complex reasoning"
    },
    {
      "id": "gpt-4.1-mini",
      "name": "GPT-4.1 Mini",
      "provider": "openai",
      "isLocal": false,
      "contextWindow": 128000,
      "maxOutputTokens": 16384,
      "speed": "fast",
      "cost": "medium",
      "description": "Fast and affordable for most tasks"
    },
    {
      "id": "gpt-4.1-nano",
      "name": "GPT-4.1 Nano",
      "provider": "openai",
      "isLocal": false,
      "contextWindow": 128000,
      "maxOutputTokens": 16384,
      "speed": "very-fast",
      "cost": "low",
      "description": "Fastest OpenAI model, great for simple tasks"
    },
    {
      "id": "o3",
      "name": "o3",
      "provider": "openai",
      "isLocal": false,
      "contextWindow": 200000,
      "maxOutputTokens": 100000,
      "speed": "slow",
      "cost": "very-high",
      "description": "Advanced reasoning model for complex problems"
    },
    {
      "id": "o4-mini",
      "name": "o4-mini",
      "provider": "openai",
      "isLocal": false,
      "contextWindow": 200000,
      "maxOutputTokens": 100000,
      "speed": "medium",
      "cost": "high",
      "description": "Balanced reasoning model"
    },
    {
      "id": "qwen/qwen3-8b",
      "name": "Qwen3 8B",
      "provider": "lmstudio",
      "isLocal": true,
      "contextWindow": 32000,
      "maxOutputTokens": 8192,
      "speed": "medium",
      "cost": "free",
      "description": "Local 8B parameter model via LM Studio"
    },
    {
      "id": "llama/llama-3.3-70b",
      "name": "Llama 3.3 70B",
      "provider": "lmstudio",
      "isLocal": true,
      "contextWindow": 128000,
      "maxOutputTokens": 8192,
      "speed": "slow",
      "cost": "free",
      "description": "Large local model for complex reasoning"
    },
    {
      "id": "mistral/mistral-small-3.1",
      "name": "Mistral Small 3.1",
      "provider": "lmstudio",
      "isLocal": true,
      "contextWindow": 128000,
      "maxOutputTokens": 8192,
      "speed": "fast",
      "cost": "free",
      "description": "Fast local model for everyday tasks"
    }
  ],
  "profiles": [
    {
      "id": "fast-local",
      "name": "Fast Local",
      "description": "Quick responses using local models",
      "defaultModelId": "qwen/qwen3-8b",
      "defaultTemperature": 0.7
    },
    {
      "id": "smart-cloud",
      "name": "Smart Cloud",
      "description": "Best quality using cloud models",
      "defaultModelId": "gpt-4.1",
      "defaultTemperature": 0.7
    },
    {
      "id": "balanced",
      "name": "Balanced",
      "description": "Good balance of speed and quality",
      "defaultModelId": "gpt-4.1-mini",
      "defaultTemperature": 0.7
    }
  ],
  "defaultModelId": "gpt-4.1-mini",
  "defaultTemperature": 0.7
}
